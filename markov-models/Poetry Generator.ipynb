{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "926f1690-1976-4fc5-ad5c-c786bd586597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ba395e8-b347-469c-9583-54ee7bda7ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial = {} # start of a phrase\n",
    "first_order = {} # second word only\n",
    "second_order = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba4fe952-2918-455c-8c48-b5dd541feaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(s):\n",
    "    return s.translate(str.maketrans('','',string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3272b20-67aa-4c8e-a63e-4fa7662f517c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File 'robert_frost.txt' already there; not retrieving.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -nc https://raw.githubusercontent.com/lazyprogrammer/machine_learning_examples/master/hmm_class/robert_frost.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c90219c0-4d15-4fcf-8a2d-8e8eb7582709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add2dict(d, k, v):\n",
    "    if k not in d:\n",
    "        d[k] = []\n",
    "    d[k].append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb62d1fe-60ee-43b4-84c4-086978774d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in open('robert_frost.txt'):\n",
    "  tokens = remove_punctuation(line.rstrip().lower()).split()\n",
    "\n",
    "  T = len(tokens)\n",
    "  for i in range(T):\n",
    "    t = tokens[i]\n",
    "    if i == 0:\n",
    "      # measure the distribution of the first word\n",
    "      initial[t] = initial.get(t, 0.) + 1\n",
    "    else:\n",
    "      t_1 = tokens[i-1]\n",
    "      if i == T - 1:\n",
    "        # measure probability of ending the line\n",
    "        add2dict(second_order, (t_1, t), 'END')\n",
    "      if i == 1:\n",
    "        # measure distribution of second word\n",
    "        # given only first word\n",
    "        add2dict(first_order, t_1, t)\n",
    "      else:\n",
    "        t_2 = tokens[i-2]\n",
    "        add2dict(second_order, (t_2, t_1), t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c89bfa3-0456-47f2-a596-74b91b54fe1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert [cat, cat, cat, dog, dog, dog, dog, mouse, ...]\n",
    "# into {cat: 0.5, dog: 0.4, mouse: 0.1}\n",
    "\n",
    "def list2pdict(ts):\n",
    "  # turn each list of possibilities into a dictionary of probabilities\n",
    "  d = {}\n",
    "  n = len(ts)\n",
    "  for t in ts:\n",
    "    d[t] = d.get(t, 0.) + 1\n",
    "  for t, c in d.items():\n",
    "    d[t] = c / n\n",
    "  return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7a283d5-3a9b-438b-a702-03d2c201d056",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t_1, ts in first_order.items():\n",
    "  # replace list with dictionary of probabilities\n",
    "  first_order[t_1] = list2pdict(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f49548cb-c98e-4bbb-b56e-58dfd7ec9f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, ts in second_order.items():\n",
    "  second_order[k] = list2pdict(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cbc7e6ae-333d-4082-9c3e-4e40367f1039",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_word(d):\n",
    "  # print \"d:\", d\n",
    "  p0 = np.random.random()\n",
    "  # print \"p0:\", p0\n",
    "  cumulative = 0\n",
    "  for t, p in d.items():\n",
    "    cumulative += p\n",
    "    if p0 < cumulative:\n",
    "      return t\n",
    "  assert(False) # should never get here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b06249d-28be-4e7f-a2a5-42635da657d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate():\n",
    "  for i in range(4): # generate 4 lines\n",
    "    sentence = []\n",
    "\n",
    "    # initial word\n",
    "    w0 = sample_word(initial)\n",
    "    sentence.append(w0)\n",
    "\n",
    "    # sample second word\n",
    "    w1 = sample_word(first_order[w0])\n",
    "    sentence.append(w1)\n",
    "\n",
    "    # second-order transitions until END\n",
    "    while True:\n",
    "      w2 = sample_word(second_order[(w0, w1)])\n",
    "      if w2 == 'END':\n",
    "        break\n",
    "      sentence.append(w2)\n",
    "      w0 = w1\n",
    "      w1 = w2\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8c04af51-37cf-4383-bb03-1b5dffbf8606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two at a times the rule one on earth will ever find\n",
      "two winds would meet\n",
      "two oldbelievers they did all the worse you must go now\n",
      "two oldbelievers they did all the talking\n"
     ]
    }
   ],
   "source": [
    "generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bc4abf-84f4-4e35-b55e-4c4257c0a835",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
